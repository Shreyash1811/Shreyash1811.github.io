---
title: "A complete guide to AWS Rokognition and image recognition with Boto3"
date: 2020-08-09
categories: [Python]
tags: [AWS,Image Classification]
header:
  image: "/images/aws_rekog/banner.png"
excerpt: "The objective of the post was to breakdown the advance process and concepts of Object Detection, Face Recognition and present them in a simpler terms and practical examples using AWS Rekognition for frustration free understanding. I have tried to provide a complete walkthrough of all the features AWS Rekognition provides using Python and Boto3 library"
mathjax: "true"
---

## Complete guide through for AWS Rekognizing with AWS Boto3 in Python:
*Image recognition can be a tedious job and generally requires strong programming skills as well as hours of training your model to get the task of recognizing done confidently, This post will guide you through easy Image recognition using AWS Rekognition and BOTO3*

### What is Rekognition?
Amazon Rekognition makes it easy to add image and video analysis to your applications. You just provide an image or video to the Amazon Rekognition API, and the service can identify objects, people, text, scenes, and activities. It can detect any inappropriate content as well. Amazon Rekognition also provides highly accurate facial analysis, face comparison, and face search capabilities. You can detect, analyze, and compare faces for a wide variety of use cases, including user verification, cataloging, people counting, and public safety.



**Why not build your own model that does this for you?**
- Because this will require you to put in hours not only first to collect the training images
- and then take more hours to train the model with those images

**With Rekcgnition:**
- It is quick.
- Keeps code simple.
- Just basic coding knowledge is enough to build great projects.




### Post will exclusively go through:
1) [Detecting Objects and Scenes.](#top1)

2) [Detecting and Analyzing Faces.](#top2)
  a) It gives you the exact position of the face in the image.
  b) Also gives sentimental score and various other details like gender, Age, glasses and beard etc.

3) [Recognizing Celebrities.](#top3)


4) [Detecting Text in a Image.](#top4)


### 1) Detecting Objects and Scenes:
We will work through making an S3 bucket to uploading the image to the S3 covering each step to building a great project.

Lets dive right into the code
<a id = "top1"></a>

```python
import boto3
```


```python
# Lets build a client
client = boto3.client('rekognition')
```


```python
s3 = boto3.client('s3',region_name='us-east-1',
                  aws_access_key_id='****',
                  aws_secret_access_key='****',
                 aws_session_token ='****')
```


```python
#List down the existing buckets
s3.list_buckets()
```




    {'ResponseMetadata': {'RequestId': '23173BD68FCC1219',
      'HostId': '0BM4avXzcIgLDEPT4rJkGOn+CHirK2C8X0tyMmx8AaNQ3TikVAnlxXOT89VV5zR3N4m5/05zCZk=',
      'HTTPStatusCode': 200,
      'HTTPHeaders': {'x-amz-id-2': '0BM4avXzcIgLDEPT4rJkGOn+CHirK2C8X0tyMmx8AaNQ3TikVAnlxXOT89VV5zR3N4m5/05zCZk=',
       'x-amz-request-id': '23173BD68FCC1219',
       'date': 'Sat, 08 Aug 2020 18:33:30 GMT',
       'content-type': 'application/xml',
       'transfer-encoding': 'chunked',
       'server': 'AmazonS3'},
      'RetryAttempts': 0},
     'Buckets': [{'Name': 'rekogniz1811',
       'CreationDate': datetime.datetime(2020, 8, 8, 15, 19, 52, tzinfo=tzutc())}],
     'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
      'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}}




```python
# Create S3 Busket
s3.create_bucket(Bucket='rekogniz1811')
```




    {'ResponseMetadata': {'RequestId': 'CD6260C43DBBCEF8',
      'HostId': 'NvUkLM9M6E70hlyzr1MPSjifIvBGDR53vypuK556pm3sw61UV5mSaXOmPc6rpkt3Bqqq6ZhSN3g=',
      'HTTPStatusCode': 200,
      'HTTPHeaders': {'x-amz-id-2': 'NvUkLM9M6E70hlyzr1MPSjifIvBGDR53vypuK556pm3sw61UV5mSaXOmPc6rpkt3Bqqq6ZhSN3g=',
       'x-amz-request-id': 'CD6260C43DBBCEF8',
       'date': 'Sun, 09 Aug 2020 12:24:15 GMT',
       'location': '/rekogniz1811',
       'content-length': '0',
       'server': 'AmazonS3'},
      'RetryAttempts': 0},
     'Location': '/rekogniz1811'}




```python
# Uploading a jpg image in the s3 bucket we created
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/trial.jpg', Key='trial.jpg',Bucket='rekogniz1811')
```


```python
# We can see the image in the bucket now
s3.list_objects(Bucket = 'rekogniz1811')['Contents']
```




    [{'Key': 'obama',
      'LastModified': datetime.datetime(2020, 8, 8, 17, 51, 22, tzinfo=tzutc()),
      'ETag': '"d41d8cd98f00b204e9800998ecf8427e"',
      'Size': 0,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}},
     {'Key': 'obama.jpg',
      'LastModified': datetime.datetime(2020, 8, 8, 17, 53, 17, tzinfo=tzutc()),
      'ETag': '"482430263f97b2f9b5b25c97398d1ec7"',
      'Size': 65826,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}},
     {'Key': 'trial.jpg',
      'LastModified': datetime.datetime(2020, 8, 8, 15, 24, 30, tzinfo=tzutc()),
      'ETag': '"1cfb29b2f6c8556c9c0a375b9c69e548"',
      'Size': 96392,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}}]




```python
# Build Rekognition Client to access the service
rekog = boto3.client('rekognition',region_name='us-east-1',
                  aws_access_key_id='****',
                  aws_secret_access_key='****',
                 aws_session_token ='****')
```

### Here we are providing details of the bucket and the image we built in above step to our client
- We can decide the Maxium Labels we want to detect.
- We can also have a MinConfidence to set as a threshold. Which in this case is set at 95%, so basically the model will only show labels it is 95% sure about.


```python

response = rekog.detect_labels(Image={'S3Object': {'Bucket': 'rekogniz1811','Name': 'trial.jpg'}
                                     },
                                      MaxLabels=10,
                                      MinConfidence=95)
```

### This is the image we are trying the object detection:
- Clearly! there are some people
- A bus
- Vehicles


```python
%pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('C:/Users/shrey/Desktop/aws_tuts/trial.jpg')
imgplot = plt.imshow(img)
plt.show()
```

    Populating the interactive namespace from numpy and matplotlib



![png](\images\aws_rekog\output_15_1.png)


### Lets see how good AWS Rekognition did the job:
- The results are right to the point.
- It managed to recognize even individual person within the bunch.


```python
for a in response['Labels']:
    print('----')
    print(a['Name'],a['Confidence'])
```

    ----
    Human 99.83802032470703
    ----
    Person 99.83802032470703
    ----
    Transportation 99.66590881347656
    ----
    Vehicle 99.66590881347656
    ----
    Bus 99.66590881347656


### 2) Detecting and Analyzing Faces:
This section will be about detecting the faces within the pictures, we will also compare two faces to see if they are similar in different pictures.
<a id = "top2"></a>
When you provide an image that contains a face, Amazon Rekognition detects the face in the image, analyzes the facial attributes of the face, and then returns a percent confidence score for the face and the facial attributes that are detected in the image.


```python
# Uploading a jpg image in the s3 bucket we created
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/obama.jpg', Key='obama.jpg',Bucket='rekogniz1811')
```


```python
%pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('C:/Users/shrey/Desktop/aws_tuts/obama.jpg')
imgplot = plt.imshow(img)
plt.show()
```

    Populating the interactive namespace from numpy and matplotlib



![png](\images\aws_rekog\output_20_1.png)



```python
response = rekog.detect_faces(Image={'S3Object':{'Bucket': 'rekogniz1811','Name': 'obama.jpg'}},Attributes=['ALL'])
```


```python
response
```




    {'FaceDetails': [{'BoundingBox': {'Width': 0.2512350380420685,
        'Height': 0.6500579714775085,
        'Left': 0.44272151589393616,
        'Top': 0.11764467507600784},
       'AgeRange': {'Low': 44, 'High': 62},
       'Smile': {'Value': False, 'Confidence': 87.3796615600586},
       'Eyeglasses': {'Value': False, 'Confidence': 98.51244354248047},
       'Sunglasses': {'Value': False, 'Confidence': 99.68080139160156},
       'Gender': {'Value': 'Male', 'Confidence': 99.91377258300781},
       'Beard': {'Value': False, 'Confidence': 62.54267883300781},
       'Mustache': {'Value': False, 'Confidence': 93.93168640136719},
       'EyesOpen': {'Value': True, 'Confidence': 99.39681243896484},
       'MouthOpen': {'Value': False, 'Confidence': 95.6460952758789},
       'Emotions': [{'Type': 'CALM', 'Confidence': 97.10798645019531},
        {'Type': 'HAPPY', 'Confidence': 2.244515895843506},
        {'Type': 'SAD', 'Confidence': 0.2011696994304657},
        {'Type': 'CONFUSED', 'Confidence': 0.1791420727968216},
        {'Type': 'ANGRY', 'Confidence': 0.10601156204938889},
        {'Type': 'SURPRISED', 'Confidence': 0.07770312577486038},
        {'Type': 'DISGUSTED', 'Confidence': 0.05970337614417076},
        {'Type': 'FEAR', 'Confidence': 0.023777062073349953}],
       'Landmarks': [{'Type': 'eyeLeft',
         'X': 0.5207709670066833,
         'Y': 0.3696680963039398},
        {'Type': 'eyeRight', 'X': 0.6340080499649048, 'Y': 0.3866291344165802},
        {'Type': 'mouthLeft', 'X': 0.5198792815208435, 'Y': 0.5989026427268982},
        {'Type': 'mouthRight', 'X': 0.6140178442001343, 'Y': 0.6126511693000793},
        {'Type': 'nose', 'X': 0.5791761875152588, 'Y': 0.490583211183548},
        {'Type': 'leftEyeBrowLeft',
         'X': 0.4777732193470001,
         'Y': 0.313757985830307},
        {'Type': 'leftEyeBrowRight',
         'X': 0.5158734321594238,
         'Y': 0.2875099182128906},
        {'Type': 'leftEyeBrowUp',
         'X': 0.5496900677680969,
         'Y': 0.30279725790023804},
        {'Type': 'rightEyeBrowLeft',
         'X': 0.6148406863212585,
         'Y': 0.3126673996448517},
        {'Type': 'rightEyeBrowRight',
         'X': 0.6470750570297241,
         'Y': 0.30733272433280945},
        {'Type': 'rightEyeBrowUp',
         'X': 0.6752206087112427,
         'Y': 0.34330472350120544},
        {'Type': 'leftEyeLeft', 'X': 0.49943944811820984, 'Y': 0.3667106032371521},
        {'Type': 'leftEyeRight', 'X': 0.5428531169891357, 'Y': 0.3750223219394684},
        {'Type': 'leftEyeUp', 'X': 0.521176278591156, 'Y': 0.35769233107566833},
        {'Type': 'leftEyeDown', 'X': 0.520656943321228, 'Y': 0.3796314001083374},
        {'Type': 'rightEyeLeft', 'X': 0.6112870573997498, 'Y': 0.3853243589401245},
        {'Type': 'rightEyeRight',
         'X': 0.6530861854553223,
         'Y': 0.3896290957927704},
        {'Type': 'rightEyeUp', 'X': 0.6349931359291077, 'Y': 0.3747439682483673},
        {'Type': 'rightEyeDown',
         'X': 0.6328930854797363,
         'Y': 0.39635270833969116},
        {'Type': 'noseLeft', 'X': 0.5516881942749023, 'Y': 0.5169459581375122},
        {'Type': 'noseRight', 'X': 0.5938181281089783, 'Y': 0.5231649875640869},
        {'Type': 'mouthUp', 'X': 0.570966899394989, 'Y': 0.5730616450309753},
        {'Type': 'mouthDown', 'X': 0.5667410492897034, 'Y': 0.6421957015991211},
        {'Type': 'leftPupil', 'X': 0.5207709670066833, 'Y': 0.3696680963039398},
        {'Type': 'rightPupil', 'X': 0.6340080499649048, 'Y': 0.3866291344165802},
        {'Type': 'upperJawlineLeft',
         'X': 0.4407918155193329,
         'Y': 0.37614893913269043},
        {'Type': 'midJawlineLeft',
         'X': 0.4541364014148712,
         'Y': 0.6218405365943909},
        {'Type': 'chinBottom', 'X': 0.5580515265464783, 'Y': 0.7623973488807678},
        {'Type': 'midJawlineRight',
         'X': 0.6560430526733398,
         'Y': 0.6518451571464539},
        {'Type': 'upperJawlineRight',
         'X': 0.689136803150177,
         'Y': 0.41340702772140503}],
       'Pose': {'Roll': 4.522486686706543,
        'Yaw': 3.728369951248169,
        'Pitch': 7.0144524574279785},
       'Quality': {'Brightness': 76.59814453125, 'Sharpness': 86.86019134521484},
       'Confidence': 99.98944854736328}],
     'ResponseMetadata': {'RequestId': 'ad0e3d2c-d08b-48df-bccb-a8bcab9e6b22',
      'HTTPStatusCode': 200,
      'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',
       'date': 'Sun, 09 Aug 2020 12:25:18 GMT',
       'x-amzn-requestid': 'ad0e3d2c-d08b-48df-bccb-a8bcab9e6b22',
       'content-length': '3334',
       'connection': 'keep-alive'},
      'RetryAttempts': 0}}



### Face information and sentiments:
**Rekognition gives us a lot more information about the face than just the location of the face in the picture.**
- Here we will see what it says about Obamas emotions in the picture.




```python
#gives Face-details
FEATURES_BLACKLIST = ("Landmarks", "Emotions", "Pose", "Quality", "BoundingBox", "Confidence")
for face in response['FaceDetails']:
    print ("Face ({Confidence}%)".format(**face))
    # emotions
    for emotion in face['Emotions']:
        print ("  {Type} : {Confidence}%".format(**emotion))
    # quality
    for quality, value in face['Quality'].items():
        print ("  {quality} : {value}".format(quality=quality, value=value))
```

    Face (99.98944854736328%)
      CALM : 97.10798645019531%
      HAPPY : 2.244515895843506%
      SAD : 0.2011696994304657%
      CONFUSED : 0.1791420727968216%
      ANGRY : 0.10601156204938889%
      SURPRISED : 0.07770312577486038%
      DISGUSTED : 0.05970337614417076%
      FEAR : 0.023777062073349953%
      Brightness : 76.59814453125
      Sharpness : 86.86019134521484


He sure looks **calm** in the picture and hence 97.10% calmness is shown by Rekognition.


### Face comparision:
Lets upload one more picture in the bucket and compare both the faces to check if Rekognition can match the similarity between them.
- Upload another image of obama and some other politician
- Give source and target pictures to Rekognition to decide
- Measure the percentage of similarities between them
- Decide if they are the same people

**Below are the points on face that Rekognition can provide about any face it detects in the image**

![png](\images\aws_rekog\face_points.png)

```python
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/obama1.jpg', Key='obama1.jpg',Bucket='rekogniz1811')
```


```python
%pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('C:/Users/shrey/Desktop/aws_tuts/obama1.jpg')
imgplot = plt.imshow(img)
plt.show()
```

    Populating the interactive namespace from numpy and matplotlib



![png](\images\aws_rekog\output_27_1.png)



```python
# We can see the image in the bucket now
s3.list_objects(Bucket = 'rekogniz1811')['Contents']
```




    [{'Key': 'obama.jpg',
      'LastModified': datetime.datetime(2020, 8, 9, 12, 24, 27, tzinfo=tzutc()),
      'ETag': '"482430263f97b2f9b5b25c97398d1ec7"',
      'Size': 65826,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}},
     {'Key': 'obama1.jpg',
      'LastModified': datetime.datetime(2020, 8, 9, 12, 30, 10, tzinfo=tzutc()),
      'ETag': '"06d8ce5841fd903714c5709d2ac5688b"',
      'Size': 126307,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}},
     {'Key': 'trump.jpg',
      'LastModified': datetime.datetime(2020, 8, 9, 12, 45, 48, tzinfo=tzutc()),
      'ETag': '"3b4d76b6714d4de6f6c8d957366ca22b"',
      'Size': 89182,
      'StorageClass': 'STANDARD',
      'Owner': {'DisplayName': 'awslabsc0w587584t1581294573',
       'ID': '106cccdf94b1b7fd0314b357b57671826ed32f0135df1cb9b576a714c64e1e6d'}}]




```python
response = rekog.compare_faces(SourceImage={
                "S3Object": {
                "Bucket": 'rekogniz1811',
                "Name": 'obama.jpg',
                }
            },
        TargetImage={
                "S3Object": {
                "Bucket": 'rekogniz1811',
                "Name": 'obama1.jpg',
                    }
            },
        SimilarityThreshold=80,)
```

Lets dig in through the response to find the similarity between these too picture.



```python
for faceMatch in response['FaceMatches']:
        position = faceMatch['Face']['BoundingBox']
        similarity = str(faceMatch['Similarity'])
        print('The face at ' +
               str(position['Left']) + ' ' +
               str(position['Top']) +
               ' matches with ' + similarity + '% confidence')
```

    The face at 0.37620148062705994 0.13611406087875366 matches with 99.99812316894531% confidence


**99.99% similar. Well! this was expected as they are 2 different pictures of Obama**

### Lets make it difficult now and see what happens when the other picture is not of Obama:


```python
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/trump.jpg', Key='trump.jpg',Bucket='rekogniz1811')
```

Lets compare Obama's picture with the below picture of trump.
- This should rather give us UnmatchedFaces Confidence
- The bigger the better the model is doing its job


```python
%pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('C:/Users/shrey/Desktop/aws_tuts/trump.jpg')
imgplot = plt.imshow(img)
plt.show()
```

    Populating the interactive namespace from numpy and matplotlib



![png](\images\aws_rekog\output_35_1.png)



```python
response_dis = rekog.compare_faces(SourceImage={
                "S3Object": {
                "Bucket": 'rekogniz1811',
                "Name": 'obama.jpg',
                }
            },
        TargetImage={
                "S3Object": {
                "Bucket": 'rekogniz1811',
                "Name": 'trump.jpg',
                    }
            },
        SimilarityThreshold=80,)
```


```python
for faceMatch in response_dis['UnmatchedFaces']:
        position = faceMatch['BoundingBox']
        dis_similarity = str(faceMatch['Confidence'])
        print(' Dis-similarity between source and taget faces ' + dis_similarity + '% confidence')
```

     Dis-similarity between source and taget faces 99.99716186523438% confidence


### 3) Recognizing Celebrities:
This is the fun excercise now. I will use the same image of Obama and Donald Trump to see if Rekognition can detect who they are. We can definetly use this to learn about celebrities we do not know about in a picture.
<a id = "top3"></a>

Celebrity recognition comes pre-trained with the ability to recognize hundreds of thousands of popular people in fields such as sports, media, politics, and business. It is designed to match celebrity faces and their various alter egos (for example, Johnny Depp without makeup, Johnny Depp as “Edward Scissorhands,” and Johnny Depp as “Jack Sparrow”).
- Your face won't be recognized because you are not a celebrity.

#### Lets first try the picture with Obama in it:


```python
response = rekog.recognize_celebrities(Image={'S3Object':{'Bucket': 'rekogniz1811','Name': 'obama.jpg'}})

for celebrity in response['CelebrityFaces']:
    print ('Name: ' + celebrity['Name'])
    print ('Id: ' + celebrity['Id'])
    print ('Position:')
    print ('   Left: ' + '{:.2f}'.format(celebrity['Face']['BoundingBox']['Height']))
    print ('   Top: ' + '{:.2f}'.format(celebrity['Face']['BoundingBox']['Top']))
    print ('Info')
    for url in celebrity['Urls']:
        print ('   ' + url)
```

    Name: Barack Obama
    Id: 3R3sg9u
    Position:
       Left: 0.68
       Top: 0.10
    Info
       www.imdb.com/name/nm1682433


That went perfect.
**Now next I will try the picture with Donald Trump in it.**


```python
response = rekog.recognize_celebrities(Image={'S3Object':{'Bucket': 'rekogniz1811','Name': 'trump.jpg'}})

for celebrity in response['CelebrityFaces']:
    print ('Name: ' + celebrity['Name'])
    print ('Id: ' + celebrity['Id'])
    print ('Position:')
    print ('   Left: ' + '{:.2f}'.format(celebrity['Face']['BoundingBox']['Height']))
    print ('   Top: ' + '{:.2f}'.format(celebrity['Face']['BoundingBox']['Top']))
    print ('Info')
    for url in celebrity['Urls']:
        print ('   ' + url)
```

    Name: Donald Trump
    Id: I4ma5e
    Position:
       Left: 0.54
       Top: 0.17
    Info
       www.imdb.com/name/nm0874339


### 4) Detecting Text:
In this section we will detect the text on an image and try various images with difficult text to check how good Rekognition is with these tasks.
<a id = "top4"></a>

Amazon Rekognition text detection can detect text in images and videos. It can then convert the detected text into machine-readable text. You can use the machine-readable text detection in images to implement solutions such as:


```python
%pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('C:/Users/shrey/Desktop/aws_tuts/text_img.jpg')
imgplot = plt.imshow(img)
plt.show()
```

    Populating the interactive namespace from numpy and matplotlib


    C:\Users\shrey\anaconda3\envs\aws_dev\lib\site-packages\IPython\core\magics\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['text']
    `%matplotlib` prevents importing * from pylab and numpy
      warn("pylab import has clobbered these variables: %s"  % clobbered +



![png](\images\aws_rekog\output_44_2.png)



```python
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/text_img.jpg', Key='text_img.jpg',Bucket='rekogniz1811')

response=rekog.detect_text(Image={'S3Object':{'Bucket': 'rekogniz1811','Name': 'text_img.jpg'}})

textDetections=response['TextDetections']

```

**Rekognition will not only scan, recognise each line and give in the response but would also give detailed information on each word. For this example we will just print all the scanned lines**


```python
print ('Detected text\n----------')
for text in textDetections:
    if text['Type'] == 'LINE':
        print ('Detected text:' + text['DetectedText'])
        print ('Confidence: ' + "{:.2f}".format(text['Confidence']) + "%")     
```

    Detected text
    ----------
    Detected text:SUCCESS IS NO ACCIDENT.
    Confidence: 99.76%
    Detected text:IT IS HARD WORK,
    Confidence: 99.46%
    Detected text:PERSEVERANCE, LEARNING,
    Confidence: 98.85%
    Detected text:STUDYING, SACRIFICE
    Confidence: 99.93%
    Detected text:AND MOST OF
    Confidence: 99.84%
    Detected text:ALL, LOVE
    Confidence: 99.66%
    Detected text:OF WHAT YOU ARE DOING
    Confidence: 99.95%
    Detected text:OR LEARNING TO DO.
    Confidence: 99.28%
    Detected text:Dreamsquote.com
    Confidence: 98.25%


The results are amazing! I did not expect it to scan the small website reference link as well, that too with 98% confidence.


```python
s3.upload_file(Filename= r'C:/Users/shrey/Desktop/aws_tuts/hindi_text.jpg', Key='hindi_text.jpg',Bucket='rekogniz1811')

response=rekog.detect_text(Image={'S3Object':{'Bucket': 'rekogniz1811','Name': 'hindi_text.jpg'}})

textDetections=response['TextDetections']
```
**Lets see if works for text in different languages. For this example I will try an image with Hindi quote in it**  

![jpg](\images\aws_rekog\hindi_text.jpg)

```python
print ('Detected text\n----------')
for text in textDetections:
    if text['Type'] == 'LINE':
        print ('Detected text:' + text['DetectedText'])
        print ('Confidence: ' + "{:.2f}".format(text['Confidence']) + "%")    
```

    Detected text
    ----------
    Detected text:Gi 3% CC thit
    Confidence: 69.34%
    Detected text:tff uT Faer ed ,
    Confidence: 74.49%
    Detected text:a d
    Confidence: 70.96%
    Detected text:3CT
    Confidence: 89.43%
    Detected text:HITM ur EO I
    Confidence: 63.35%

**That makes no sense! Clearly AWS rekognition is not compatible with different languages but they have different services for this task.**  

**I hope this was a great learning experience, stay updated for more posts and keep learning.**
